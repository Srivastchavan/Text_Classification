{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import collections\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"train/\"\n",
    "testing_path = \"test/\"\n",
    "folders = ['spam','ham']\n",
    "\n",
    "stop_words = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can't\",\"cannot\",\"could\",\"couldn't\",\"did\",\"didn't\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn't\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\"more\",\"most\",\"mustn't\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"shan't\",\"she\",\"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"wasn't\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"were\",\"weren't\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\"won't\",\"would\",\"wouldn't\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]\n",
    "\n",
    "bias=0\n",
    "lrn_rt=0.001\n",
    "lamda=0.01\n",
    "itr_count=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ham=0\n",
    "count_spam=0\n",
    "ham_wordsList=[]\n",
    "spam_wordsList=[]\n",
    "\n",
    "count_ham_test=0\n",
    "count_spam_test=0\n",
    "ham_wordsList_test=[]\n",
    "spam_wordsList_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Count_WordsList(filepath):\n",
    "    word_Lst = list()\n",
    "    file_Count = 0\n",
    "    for files in os.listdir(filepath):\n",
    "        if files.endswith(\".txt\"):\n",
    "            file_Count+=1\n",
    "            word_Lst += get_Words(files,filepath)\n",
    "    return file_Count, word_Lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Words(file,filepath):\n",
    "    fileHandler = codecs.open(filepath+\"\\\\\" + file,'rU','latin-1')\n",
    "    Findwords = re.findall('[A-Za-z0-9\\']+', fileHandler.read())\n",
    "    allwords = list()\n",
    "    for word in Findwords:\n",
    "        word = word.lower()\n",
    "        allwords+=[word]\n",
    "    fileHandler.close()    \n",
    "    return allwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_spam,spam_wordsList = get_Count_WordsList(training_path+folders[0])\n",
    "count_ham,ham_wordsList = get_Count_WordsList(training_path+folders[1])\n",
    "\n",
    "count_spam_test,spam_wordsList_test = get_Count_WordsList(testing_path+folders[0])\n",
    "count_ham_test,ham_wordsList_test = get_Count_WordsList(testing_path+folders[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_StopWords():\n",
    "    for wrd in stop_words:\n",
    "        if wrd in ham_wordsList:\n",
    "            i = 0\n",
    "            ham_len=len(ham_wordsList)\n",
    "            while (i < ham_len):\n",
    "                if (ham_wordsList[i] == wrd):\n",
    "                    ham_wordsList.remove(wrd)\n",
    "                    ham_len = ham_len - 1\n",
    "                    continue\n",
    "                i = i + 1\n",
    "        if wrd in spam_wordsList:\n",
    "            i = 0\n",
    "            spam_len=len(spam_wordsList)\n",
    "            while (i < spam_len):\n",
    "                if (spam_wordsList[i] == wrd):\n",
    "                    spam_wordsList.remove(wrd)\n",
    "                    spam_len = spam_len - 1\n",
    "                    continue\n",
    "                i = i + 1\n",
    "        if wrd in ham_wordsList_test:\n",
    "            i = 0\n",
    "            ham_len_test=len(ham_wordsList_test)\n",
    "            while (i < ham_len_test):\n",
    "                if (ham_wordsList_test[i] == wrd):\n",
    "                    ham_wordsList_test.remove(wrd)\n",
    "                    ham_len_test = ham_len_test - 1\n",
    "                    continue\n",
    "                i = i + 1\n",
    "        if wrd in spam_wordsList_test:\n",
    "            i = 0\n",
    "            spam_len_test=len(spam_wordsList_test)\n",
    "            while (i < spam_len_test):\n",
    "                if (spam_wordsList_test[i] == wrd):\n",
    "                    spam_wordsList_test.remove(wrd)\n",
    "                    spam_len_test = spam_len_test - 1\n",
    "                    continue\n",
    "                i = i + 1\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_StopWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wordsList = ham_wordsList + spam_wordsList\n",
    "dict_allWords = collections.Counter(all_wordsList)\n",
    "list_key = list(dict_allWords.keys())\n",
    "y_list = list()  \n",
    "file_count = count_spam + count_ham\n",
    "\n",
    "all_wordsList_test = ham_wordsList_test + spam_wordsList_test\n",
    "dict_allWords_test = collections.Counter(all_wordsList_test)\n",
    "list_key_test = list(dict_allWords_test.keys())\n",
    "y_list_test = list()  \n",
    "file_count_test = count_spam_test + count_ham_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matrix_init(rw, col):\n",
    "    x_mat = [0] * rw\n",
    "    for i in range(rw):\n",
    "        x_mat[i] = [0] * col\n",
    "    return x_mat\n",
    "\n",
    "row_mat = 0\n",
    "row_mat_test = 0\n",
    "\n",
    "def create_mat(x_mat, path, list_key, row_mat, cls, y_list):\n",
    "    for file in os.listdir(path):\n",
    "        words = get_Words(file, path)\n",
    "        temp = dict(collections.Counter(words))\n",
    "        for key in temp:\n",
    "            if key in list_key:\n",
    "                column = list_key.index(key)\n",
    "                x_mat[row_mat][column] = temp[key]\n",
    "        if (cls == folders[1]):\n",
    "            y_list[row_mat] = 0\n",
    "        elif (cls == folders[0]):\n",
    "            y_list[row_mat] = 1\n",
    "        row_mat += 1\n",
    "    return x_mat, row_mat, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat_train = feature_matrix_init(file_count, len(list_key))\n",
    "x_mat_test = feature_matrix_init(file_count_test, len(list_key_test))\n",
    "\n",
    "\n",
    "sgmd_list = list()  \n",
    "for i in range(file_count):\n",
    "    sgmd_list.append(-1)\n",
    "    y_list.append(-1)\n",
    "\n",
    "for i in range(file_count_test):\n",
    "    y_list_test.append(-1)\n",
    "\n",
    "wt_feature = list()\n",
    "\n",
    "for feature in range(len(list_key)):\n",
    "    wt_feature.append(0)\n",
    "    \n",
    "    \n",
    "x_mat_train, row_mat, y_list = create_mat(x_mat_train, training_path+folders[1], list_key, row_mat,\n",
    "                                                       folders[1], y_list)\n",
    "x_mat_train, row_mat, y_list = create_mat(x_mat_train, training_path+folders[0], list_key, row_mat,\n",
    "                                                       folders[0], y_list)\n",
    "\n",
    "x_mat_test, row_mat_test, y_list_test = create_mat(x_mat_test, testing_path+folders[1], list_key_test,\n",
    "                                                              row_mat_test, folders[1], y_list_test)\n",
    "x_mat_test, row_mat_test, y_list_test = create_mat(x_mat_test, testing_path+folders[0], list_key_test,\n",
    "                                                              row_mat_test, folders[0], y_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_training(file_count, x_count, x_mat_train, y_list):\n",
    "    calc_sgmdFunc(file_count, x_count, x_mat_train)\n",
    "    calc_wtUpdt(file_count, x_count, x_mat_train, y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_wtUpdt(file_count, x_total, x_mat, y_list):\n",
    "    global sgmd_list\n",
    "    for x in range(x_total):\n",
    "        wt = bias\n",
    "        for fls in range(file_count):\n",
    "            freq = x_mat[fls][x]\n",
    "            y = y_list[fls]\n",
    "            sgmd_val = sgmd_list[fls]\n",
    "            wt += freq * (y - sgmd_val)\n",
    "\n",
    "        wt_old = wt_feature[x]\n",
    "        wt_feature[x] += ((wt * lrn_rt) - (lrn_rt * lamda * wt_old))\n",
    "\n",
    "    return wt_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sgmdFunc(file_count, x_total, x_mat):\n",
    "    global sgmd_list\n",
    "    for fl in range(file_count):\n",
    "        sum1 = 1.0\n",
    "        for x in range(x_total):\n",
    "            sum1 += x_mat[fl][x] * wt_feature[x]\n",
    "        sgmd_list[fl] = clac_sgmd(sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clac_sgmd(z):\n",
    "    d = (1 + np.exp(-z))\n",
    "    sgmd = 1 / d\n",
    "    return sgmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_classify():\n",
    "    true_pred_ham = 0\n",
    "    false_pred_ham = 0\n",
    "    true_pred_spam = 0\n",
    "    false_pred_spam = 0\n",
    "    j=0\n",
    "    for file in range(file_count_test):\n",
    "        sum1 = 1.0\n",
    "        for i in range(len(list_key_test)):\n",
    "            word = list_key_test[i]\n",
    "\n",
    "            if word in list_key:\n",
    "                index = list_key.index(word)\n",
    "                wt = wt_feature[index]\n",
    "                wordcount = x_mat_test[file][i]\n",
    "\n",
    "                sum1 += wt * wordcount\n",
    "\n",
    "        sum_sgmd = clac_sgmd(sum1)\n",
    "        if (y_list_test[file] == 0):\n",
    "            if sum_sgmd < 0.5:\n",
    "                true_pred_ham += 1.0\n",
    "            else:\n",
    "                false_pred_ham += 1.0\n",
    "        else:\n",
    "            if sum_sgmd >= 0.5:\n",
    "                true_pred_spam += 1.0\n",
    "            else:\n",
    "                false_pred_spam += 1.0\n",
    "        print('Classification of test email '+str(j+1)+'complete.')\n",
    "        j += 1\n",
    "    print(\"Results:\\n\")\n",
    "    print(\"Ham Accuracy of Logistic Regression model:\" + str((true_pred_ham / (true_pred_ham + false_pred_ham)) * 100))\n",
    "    print(\"Spam Accuracy of Logistic Regression model:\" + str((true_pred_spam / (true_pred_spam + false_pred_spam)) * 100))\n",
    "    print(\"Overall Accuracy of Logistic Regression model:\" + str(((true_pred_ham+true_pred_spam) / (true_pred_ham + false_pred_ham+true_pred_spam + false_pred_spam)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of Logistic Regression model started... \n",
      "0 1 2 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1b786b7585ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitr_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mlog_reg_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_mat_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training completed successfully\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nClassification of Testing Data started...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-9f76722a7576>\u001b[0m in \u001b[0;36mlog_reg_training\u001b[1;34m(file_count, x_count, x_mat_train, y_list)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlog_reg_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_mat_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcalc_sgmdFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_mat_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcalc_wtUpdt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_mat_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-0eb43dc06903>\u001b[0m in \u001b[0;36mcalc_wtUpdt\u001b[1;34m(file_count, x_total, x_mat, y_list)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0msgmd_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgmd_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mwt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msgmd_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mwt_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwt_feature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training of Logistic Regression model started... \")\n",
    "for i in range(int(itr_count)):\n",
    "    print(i, end=' ')\n",
    "    log_reg_training(file_count, len(list_key), x_mat_train, y_list)\n",
    "print(\"Training completed successfully\")\n",
    "print(\"\\nClassification of Testing Data started...\")\n",
    "log_reg_classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
