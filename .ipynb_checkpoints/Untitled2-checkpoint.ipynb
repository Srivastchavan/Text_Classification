{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import collections\n",
    "import codecs\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"train/\"\n",
    "testing_path = \"test/\"\n",
    "folders = ['spam','ham']\n",
    "\n",
    "stop_words = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can't\",\"cannot\",\"could\",\"couldn't\",\"did\",\"didn't\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn't\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\"more\",\"most\",\"mustn't\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"shan't\",\"she\",\"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"wasn't\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"were\",\"weren't\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\"won't\",\"would\",\"wouldn't\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ham=0\n",
    "count_spam=0\n",
    "ham_wordsList=[]\n",
    "spam_wordsList=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Count_WordsList(filepath):\n",
    "    word_Lst = list()\n",
    "    file_Count = 0\n",
    "    for files in os.listdir(filepath):\n",
    "        if files.endswith(\".txt\"):\n",
    "            file_Count+=1\n",
    "            word_Lst += get_Words(files,filepath)\n",
    "    return file_Count, word_Lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Words(file,filepath):\n",
    "    fileHandler = codecs.open(filepath+\"\\\\\" + file,'rU','latin-1')\n",
    "    Findwords = re.findall('[A-Za-z0-9\\']+', fileHandler.read())\n",
    "    allwords = list()\n",
    "    for word in Findwords:\n",
    "        word = word.lower()\n",
    "        allwords+=[word]\n",
    "    fileHandler.close()    \n",
    "    return allwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_spam,spam_wordsList = get_Count_WordsList(training_path+folders[0])\n",
    "count_ham,ham_wordsList = get_Count_WordsList(training_path+folders[1])\n",
    "\n",
    "dict_spam = dict(collections.Counter(wrds.lower() for wrds in spam_wordsList))\n",
    "dict_ham = dict(collections.Counter(wrds.lower() for wrds in ham_wordsList))\n",
    "\n",
    "all_wordsList = spam_wordsList + ham_wordsList\n",
    "dict_allWords = collections.Counter(all_wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setCountZero(all_words,spam_ham_dict):\n",
    "    for wrds in all_words:\n",
    "        if wrds not in spam_ham_dict:\n",
    "            spam_ham_dict[wrds] = 0\n",
    "            \n",
    "            \n",
    "setCountZero(dict_allWords,dict_ham)\n",
    "setCountZero(dict_allWords,dict_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_StopWords():\n",
    "    for wrd in stop_words:\n",
    "        if wrd in dict_ham:\n",
    "            del dict_ham[wrd]\n",
    "        if wrd in dict_spam:\n",
    "            del dict_spam[wrd]\n",
    "        if wrd in dict_allWords:\n",
    "            del dict_allWords[wrd] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_Prob(cls):\n",
    "    if cls == folders[0]:\n",
    "        prob_Spam = count_spam/(count_spam + count_ham)\n",
    "        return prob_Spam\n",
    "    else:\n",
    "        prob_Ham = count_ham/(count_spam + count_ham)\n",
    "        return prob_Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_wrds_probability = dict()\n",
    "spam_wrds_probability = dict()\n",
    "def calculate_Word_Probability(cls):\n",
    "    Counter = 0                 \n",
    "    if cls == folders[1]:\n",
    "        for wrd in dict_ham:\n",
    "            Counter += (dict_ham[wrd] + 1)\n",
    "        for wrd in dict_ham:\n",
    "            ham_wrds_probability[wrd] = math.log((dict_ham[wrd] + 1)/Counter ,2)\n",
    "    elif cls == folders[0]:\n",
    "        for wrd in dict_spam:\n",
    "            Counter += (dict_spam[wrd] + 1)\n",
    "        for wrd in dict_spam:\n",
    "            spam_wrds_probability[wrd] = math.log((dict_spam[wrd] + 1)/Counter ,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_NB(path, cls):\n",
    "    ham_prob = 0 \n",
    "    spam_prob = 0 \n",
    "    false_Pred = 0\n",
    "    file_count = 0\n",
    "                   \n",
    "    if cls == folders[0]:\n",
    "        for fileName in os.listdir(path):\n",
    "            words =get_Words(fileName,path)\n",
    "            \n",
    "            ham_prob = math.log(find_Prob(folders[1]),2)\n",
    "            spam_prob = math.log(find_Prob(folders[0]),2)\n",
    "            \n",
    "            for word in words:\n",
    "                if word in ham_wrds_probability:\n",
    "                    ham_prob += ham_wrds_probability[word]\n",
    "                if word in spam_wrds_probability:\n",
    "                    spam_prob += spam_wrds_probability[word]\n",
    "            file_count +=1\n",
    "            if(ham_prob >= spam_prob):\n",
    "                false_Pred+=1\n",
    "    if cls == folders[1]:\n",
    "        for fileName in os.listdir(path):\n",
    "            words =get_Words(fileName,path)\n",
    "            \n",
    "            ham_prob = math.log(find_Prob(folders[1]),2)\n",
    "            spam_prob = math.log(find_Prob(folders[0]),2)\n",
    "                        \n",
    "            for word in words:\n",
    "                if word in ham_wrds_probability:\n",
    "                    ham_prob += ham_wrds_probability[word]\n",
    "                if word in spam_wrds_probability:\n",
    "                    spam_prob += spam_wrds_probability[word]\n",
    "            file_count +=1\n",
    "            if(ham_prob <= spam_prob):\n",
    "                false_Pred+=1\n",
    "    return false_Pred,file_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes model:\n",
      "(Results before removing stop words from testing data)\n",
      "\n",
      "Files in Ham Folder:  348\n",
      "Files in Spam Folder:  130\n",
      "Total number of files:  478\n",
      "\n",
      "Ham Folder\n",
      "Number of emails correctly classified as Ham:  340\n",
      "Number of emails wrongly classified as Spam:  8\n",
      "\n",
      "Naive Bayes Accuracy For Ham Folder:97.7%\n",
      "\n",
      "Spam Folder\n",
      "Number of emails correctly classified as Spam:  110\n",
      "Number of emails wrongly classified as Ham:  20\n",
      "\n",
      "Naive Bayes Accuracy For Spam Folder: 84.62%\n",
      "\n",
      "Multinomial Naive Bayes model Total accuracy for Test data: 94.14%\n"
     ]
    }
   ],
   "source": [
    "print(\"Multinomial Naive Bayes model:\")  \n",
    "print(\"(Results before removing stop words from testing data)\")  \n",
    "\n",
    "calculate_Word_Probability(folders[0])\n",
    "calculate_Word_Probability(folders[1]) \n",
    "\n",
    "false_pred_ham,total_ham = predict_NB(testing_path+folders[1],folders[1])\n",
    "false_pred_spam,total_spam = predict_NB(testing_path+folders[0],folders[0])\n",
    "accuracy_ham = round(((total_ham - false_pred_ham )/(total_ham ))*100,2)\n",
    "accuracy_spam = round(((total_spam -  false_pred_spam )/(total_spam))*100,2)\n",
    "total_emails = total_ham + total_spam\n",
    "false_pred_total = false_pred_ham + false_pred_spam\n",
    "accuracy_total = round(((total_emails  - false_pred_total )/total_emails)*100,2)\n",
    "\n",
    "print(\"\\nFiles in Ham Folder: \", total_ham)\n",
    "print(\"Files in Spam Folder: \", total_spam)\n",
    "print(\"Total number of files: \", total_emails)\n",
    "\n",
    "print(\"\\nHam Folder\")\n",
    "print(\"Number of emails correctly classified as Ham: \", total_ham - false_pred_ham)\n",
    "print(\"Number of emails wrongly classified as Spam: \",false_pred_ham)\n",
    "print(\"\\nNaive Bayes Accuracy For Ham Folder:\" + str(accuracy_ham) + \"%\")\n",
    "\n",
    "print(\"\\nSpam Folder\")\n",
    "\n",
    "print(\"Number of emails correctly classified as Spam: \", total_spam - false_pred_spam)\n",
    "print(\"Number of emails wrongly classified as Ham: \",false_pred_spam)\n",
    "print(\"\\nNaive Bayes Accuracy For Spam Folder: \" + str(accuracy_spam) + \"%\") \n",
    "\n",
    "print(\"\\nMultinomial Naive Bayes model Total accuracy for Test data: \" + str(accuracy_total) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes model:\n",
      "(Results after removing stop words from testing data)\n",
      "\n",
      "Files in Ham Folder:  348\n",
      "Files in Spam Folder:  130\n",
      "Total number of files:  478\n",
      "\n",
      "Ham Folder\n",
      "Number of emails correctly classified as Ham:  343\n",
      "Number of emails wrongly classified as Spam:  5\n",
      "\n",
      "Naive Bayes Accuracy For Ham Folder:98.56%\n",
      "\n",
      "Spam Folder\n",
      "Number of emails correctly classified as Spam:  108\n",
      "Number of emails wrongly classified as Ham:  22\n",
      "\n",
      "Naive Bayes Accuracy For Spam Folder: 83.08%\n",
      "\n",
      "Multinomial Naive Bayes model Total accuracy for Test data: 94.35%\n"
     ]
    }
   ],
   "source": [
    "print(\"Multinomial Naive Bayes model:\")  \n",
    "print(\"(Results after removing stop words from testing data)\")  \n",
    "\n",
    "remove_StopWords()\n",
    "calculate_Word_Probability(folders[0])\n",
    "calculate_Word_Probability(folders[1]) \n",
    "\n",
    "false_pred_ham,total_ham = predict_NB(testing_path+folders[1],folders[1])\n",
    "false_pred_spam,total_spam = predict_NB(testing_path+folders[0],folders[0])\n",
    "accuracy_ham = round(((total_ham - false_pred_ham )/(total_ham ))*100,2)\n",
    "accuracy_spam = round(((total_spam -  false_pred_spam )/(total_spam))*100,2)\n",
    "total_emails = total_ham + total_spam\n",
    "false_pred_total = false_pred_ham + false_pred_spam\n",
    "accuracy_total = round(((total_emails  - false_pred_total )/total_emails)*100,2)\n",
    "\n",
    "print(\"\\nFiles in Ham Folder: \", total_ham)\n",
    "print(\"Files in Spam Folder: \", total_spam)\n",
    "print(\"Total number of files: \", total_emails)\n",
    "\n",
    "print(\"\\nHam Folder\")\n",
    "print(\"Number of emails correctly classified as Ham: \", total_ham - false_pred_ham)\n",
    "print(\"Number of emails wrongly classified as Spam: \",false_pred_ham)\n",
    "print(\"\\nNaive Bayes Accuracy For Ham Folder:\" + str(accuracy_ham) + \"%\")\n",
    "\n",
    "print(\"\\nSpam Folder\")\n",
    "\n",
    "print(\"Number of emails correctly classified as Spam: \", total_spam - false_pred_spam)\n",
    "print(\"Number of emails wrongly classified as Ham: \",false_pred_spam)\n",
    "print(\"\\nNaive Bayes Accuracy For Spam Folder: \" + str(accuracy_spam) + \"%\") \n",
    "\n",
    "print(\"\\nMultinomial Naive Bayes model Total accuracy for Test data: \" + str(accuracy_total) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
